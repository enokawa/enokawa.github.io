<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws on あしたから本気だす</title>
    <link>http://blog.enokawa.co/tags/aws/</link>
    <description>Recent content in Aws on あしたから本気だす</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Thu, 14 Jun 2018 23:02:51 +0900</lastBuildDate>
    
	<atom:link href="http://blog.enokawa.co/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>EFSをVPCペアリング経由でマウントする</title>
      <link>http://blog.enokawa.co/2018/06/14/mount-efs-via-vpc-peering/</link>
      <pubDate>Thu, 14 Jun 2018 23:02:51 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2018/06/14/mount-efs-via-vpc-peering/</guid>
      <description>はじめに こんにちはえのかわです。前回は単純に autofs で EFS をマウントしましたが、今回は VPC Peering経由でマウントしてみたいと思います。 AWS のドキュメントには、VPN や VPC Peering 経由ではマウントできないとの記述があります。
 AWS Direct Connect を使用して、オンプレミスのデータセンターサーバーから Amazon EFS ファイルシステムをマウントできます。ただし、VPN 接続や VPC ピア接続などの他の VPC プライベート接続機能はサポートされていません。
 https://docs.aws.amazon.com/ja_jp/efs/latest/ug/limits.html
クラメソさんの記事を参考にさせてもらいました。
SSH ポートフォワーディングを使って EFS を Mac からマウントしてみた
AWS リソース作成 こんな感じで作成しました。東京リージョンからオレゴンリージョンの EC2 を経由して EFS をマウントします。RouteTable や SecurityGroup の設定はお互い通信できるように事前に済ませておきましょう。 EC2設定(東京側) オレゴン側の設定は特に必要ありません。こういう感じで東京の EC2 からオレゴンの EC2 に SSH できるように設定しておきます。
[ec2-user@ip-10-0-0-79 ~]$ ssh -i .ssh/enokawa-kensho-us-west-2.pem ec2-user@172.31.38.154 Last login: Thu Jun 14 03:40:07 2018 from 10.0.0.79 __| __|_ ) _| ( / Amazon Linux AMI ___|\___|___| https://aws.</description>
    </item>
    
    <item>
      <title>autofsでEFSをマウントする</title>
      <link>http://blog.enokawa.co/2018/06/13/mount-efs-with-autofs/</link>
      <pubDate>Wed, 13 Jun 2018 23:02:51 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2018/06/13/mount-efs-with-autofs/</guid>
      <description>はじめに こんにちはえのかわです。EFS、東京リージョン対応がアナウンスされましたね。
リリース前にちょいと検証してみます。単純にマウントするだけではつまらないので autofs でマウントしてみます。
AWS リソース作成 こんな感じで作成しました。リージョンはオレゴンでやってます。OS は Amazon Linux です。 EC2設定 autofs をインストールしてマウントポイント用のディレクトリを作成します。
[ec2-user@ip-172-31-38-110 ~]$ sudo yum install autofs [ec2-user@ip-172-31-38-110 ~]$ mkdir /exports  続いて autofs の設定です。
[ec2-user@ip-172-31-38-110 ~]$ sudo sh -c &amp;quot;echo &#39;/- /etc/auto.nfs --timeout=3&#39; &amp;gt;&amp;gt; /etc/auto.master&amp;quot; [ec2-user@ip-172-31-38-110 ~]$ cat /etc/auto.nfs /exports -nfsvers=4.1 us-west-2a.fs-xxxxxxxx.efs.us-west-2.amazonaws.com:/  autofs 起動します。
[ec2-user@ip-172-31-38-110 ~]$ sudo /etc/init.d/autofs start Starting automount: [ OK ]  /exports ディレクトリに移動するとマウントされていることが確認できました。
[ec2-user@ip-172-31-38-110 ~]$ df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 484M 56K 484M 1% /dev tmpfs 494M 0 494M 0% /dev/shm /dev/xvda1 7.</description>
    </item>
    
    <item>
      <title>Serverless FrameworkでEC2を定期的に起動/停止するdawnを公開しました</title>
      <link>http://blog.enokawa.co/2018/02/14/dawn/</link>
      <pubDate>Wed, 14 Feb 2018 00:26:12 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2018/02/14/dawn/</guid>
      <description>はじめに こんにちはえのかわです。タイトルの通り、EC2 を定期的に起動/停止するツール、名付けて dawn をリリースしました。
enokawa/dawn: Lambda function to automaticaly stop and start the EC2 instance.
dawn?? dawn とは 夜明け、明け方 という意味です。名付け親は id:iga-ninja さんです。どうも良い名前が決まらなくて決めてもらいました。発音は dän, dôn だそうです。どぁ〜ん。
きっかけ 業務のなかで、よく EC2 を定期的に停止/起動するケースがあるので、どうせなら Serverless Framework でと思い作成しました。けっこうありきたりですが、EC2 の費用削減にもなりますし僕も利用者の一人です。
また、dawn は EC2 の AMI をスケジュールで取得する y13i/amirotate を参考にして作成しました。amirotate に限らず、y13i さんのレポジトリはすごく参考になります。
おわりに 今回は単純なスクリプトですが、今後もガンガン Serverless Framework 使っていきます。何か要望などあれば Pull Request いただけると僕が喜びます。</description>
    </item>
    
    <item>
      <title>GoogleAuthenticatorを利用してAmazon WorkSpacesへ多要素認証ログインする</title>
      <link>http://blog.enokawa.co/2018/01/11/login-to-amazon-workspaces-with-google-authenticator/</link>
      <pubDate>Thu, 11 Jan 2018 22:18:02 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2018/01/11/login-to-amazon-workspaces-with-google-authenticator/</guid>
      <description>はじめに えのかわです。
Amazon WorkSpaces に多用素認証ログインするのに詰まったのでエントリ書きます。
構成 ざっくりとこんな感じです。現時点(2018/01/12)で Simple AD だと MFA を利用した上での WorkSpaces ログインができないので Microsoft AD を使用しています。 手順 VPC の作成とかは省きます。
DirectoryServiceの作成 作成には 20 分 〜 30 分ほど掛かります。
$ aws ds create-microsoft-ad \ --name ad.enokawa.co \ --password xxxxxxxxxxxxxx \ --vpc-settings VpcId=vpc-xxxxxxx,SubnetIds=subnet-xxxxxxx,subnet-xxxxxxx { &amp;quot;DirectoryId&amp;quot;: &amp;quot;d-xxxxxxxxx&amp;quot; }  Directory の Status が Active になったら Register します。(Register する API が見つけられなかったけどないのかな、、、
WorkSpaceの作成 CLI で作成する場合は WorkSpace 用のユーザが DirectoryService に存在している必要があります。DirectoryService にユーザを作成する場合は少し面倒なので公式ドキュメントを参考にポチポチで作成します。
お客様の Amazon WorkSpace ( Your Amazon WorkSpace ) という件名でメールが AWS 側から送信されるので、メール本文に記載されている手順通りに進めます。専用のクライアントでログインを試みると、ユーザ名とパスワードが表示されます。これで普通にログインできます。 RADIUSインスタンスの設定 gist はります。hostnamectl コマンドでホスト名を設定しておいてください。</description>
    </item>
    
    <item>
      <title>【re:Invent2017レポート】NetflixはパフォーマンスのためにどのようにEC2をチューニングしているか</title>
      <link>http://blog.enokawa.co/2017/11/29/how-netflix-tunes-amazon-ec2-instances-for-performance/</link>
      <pubDate>Wed, 29 Nov 2017 18:09:58 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2017/11/29/how-netflix-tunes-amazon-ec2-instances-for-performance/</guid>
      <description>はじめに こんにちはえのかわです。下記のセッションレポートです。
CMP325 - How Netflix Tunes Amazon EC2 Instances for Performance
 インスタンスタイプの選定  Netflix の AWS 環境  AutoScalingを採用  30 ものインスタンスタイプを使い分けている  ファミリーは m4 / c5 / i3, d2 / r4, x1 / p2, g3, f1 medium から 16xlarge(以上) まで  インスタンス選択のフローチャート    全てのインスタンスタイプでロードテスト(スループット計測)を行っている  EC2 インスタンスの費用についても計測し、効率の良いインスタンスタイプを選定する インスタンス選定用のツールも自前で作成している    カーネルチューニング  Netflix では Ubuntu Linux を利用している  基本的なパフォーマンスチューニングを施しているベースの AMI を持っている  CPU スケジュール  # schedtool -B PID  仮想メモリ  vm.</description>
    </item>
    
    <item>
      <title>【re:Invent2017レポート】ExpediaにおけるAmazonElasticsearchServiceを用いたログ解析</title>
      <link>http://blog.enokawa.co/2017/11/28/log-analytics-at-expedia-using-amazon-elasticsearch-service/</link>
      <pubDate>Tue, 28 Nov 2017 07:17:52 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2017/11/28/log-analytics-at-expedia-using-amazon-elasticsearch-service/</guid>
      <description>はじめに こんにちはえのかわです。下記のセッションレポートです。
ABD331 - Log Analytics at Expedia Using Amazon Elasticsearch Service
 Amazon Elasticsearch Service について まず AWS の Principal Product Manager である Carl Meadows 氏から簡単に Elasticsearch と Amazon Elasticsearch Service(以下ES)についての説明がありました。
現在、機械的に生成されたデータは多い  手動による IT から DevOps への移行 IoT デバイス クラウドベースのアーキテクチャ  Elasticsearch のベネフィット  オープンソース 素早い価値創出  ELK Stack とは下記の 3 つをまとめたもの  Elasticsearch Logstash Kibana  Elasticsearch のユースケース  アプリケーションモニタリング と Root-cause Analysis(根本原因解析) Security Information and Event Management(SIEM) IoT &amp;amp; モバイル ビジネス &amp;amp; クリックストリーム分析  ES について  マネージド Elasticsearch + Kibana ベネフィット  オープンソース 簡単 スケーラブル セキュア 高可用性 他 AWS サービスとの連携   事例  Adobe Netflix など  Expedia における ES のユースケース Expedia の Kuldeep Chowhan(@this_is_kuldeep) 氏から Expedia のユースケースについて発表がありました。</description>
    </item>
    
    <item>
      <title>CloudFront&#43;S3で構成する静的ウェブサイトホスティングのベストプラクティス</title>
      <link>http://blog.enokawa.co/2017/10/13/best-practice-for-static-web-site-hosting-with-cloudfront-and-s3/</link>
      <pubDate>Fri, 13 Oct 2017 23:08:58 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2017/10/13/best-practice-for-static-web-site-hosting-with-cloudfront-and-s3/</guid>
      <description>はじめに えのかわです。
よくある、CloudFrnt + S3 を用いた静的ウェブサイトホスティングの、ベストプラクティスをログとして残します。（よく説明することがあるので、、）
構成 S3 を CloudFront Origin として登録する際に、2 つの方法があると思っています。
 S3 Origin Custom Origin(Static website hostingのURLで)  しかし2つの方法にはメリットデメリットがあります。
 S3 Origin  メリット: OAIによるS3への直接アクセスを防ぐことが可能 デメリット: ディレクトリを掘ったパスにアクセスした際にindex.htmlがロードされない  Custom Origin  メリット: ディレクトリを掘ったパスにアクセスした際にindex.htmlがロードされる デメリット: S3 へ直接アクセスできてしまう   本題 Cloud Front の Origin として、Custom Origin で登録する方法で進めます。該当の S3 は Static website hosting を有効化します。 その上で S3 のバケットポリシー側で UserAgent 値が Amazon CloudFront であった場合にコンテンツを返すように記載します。
{ &amp;quot;Version&amp;quot;: &amp;quot;2008-10-17&amp;quot;, &amp;quot;Statement&amp;quot;: [ { &amp;quot;Sid&amp;quot;: &amp;quot;AllowFromCloudFront&amp;quot;, &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Principal&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;Action&amp;quot;: &amp;quot;s3:GetObject&amp;quot;, &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::example.</description>
    </item>
    
    <item>
      <title>AutoScalingからCloudWatchEvents(Lambda)を呼ぶ</title>
      <link>http://blog.enokawa.co/2017/04/23/use-auto-scaling-lifecycle-hook-with-cloudwatch-events-lambda/</link>
      <pubDate>Sun, 23 Apr 2017 16:02:58 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2017/04/23/use-auto-scaling-lifecycle-hook-with-cloudwatch-events-lambda/</guid>
      <description>はじめに ご無沙汰してます、えのかわです。先日投稿したエントリの続きです。
今回は、Auto Scaling の Lifecycle Hooks の TERMINATING をトリガーに、CloudWatch Events から Lambda Function をキックして、SSM Run Commandを呼んでみます。
ゴールはログを S3 に転送することとします。
AutoScaling設定 前回のエントリと同様の AWS CLI を流します。
Scaling Policies、Lifecycle hook の作成も併せて行います。
Lambda Function作成 今回はせっかくなので Serverless Framework を用いて Lambda Function を作成します。 
CloudWatch Events作成 CloudWatch Events の設定も Serverless Framework で行いたかったのですが何故か上手くいかず、、、しょうがなく GUI で設定しました。 ドキュメントはこちらです。
AutoScaling実施 今回は Scale In Event のみ Execute します。
Terminating -&amp;gt; Terminating:Wait -&amp;gt; Terminating:Proceed -&amp;gt; Terminated の順番でサービスアウトしました。 s3 の中身を見てみると、、、
sls-autoscaling % aws s3 ls s3://enokawa-logs/ PRE i-xxxxxxxxxxxxxx1/ PRE i-xxxxxxxxxxxxxx2/  問題なくスケールインされたインスタンスのログのみ転送されてました。</description>
    </item>
    
    <item>
      <title>AutoScalingからCloudWatchEvents(SSM)を呼ぶ</title>
      <link>http://blog.enokawa.co/2017/03/23/use-auto-scaling-lifecycle-hook-with-cloudwatch-events-ssm/</link>
      <pubDate>Thu, 23 Mar 2017 14:17:24 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2017/03/23/use-auto-scaling-lifecycle-hook-with-cloudwatch-events-ssm/</guid>
      <description>はじめに ご無沙汰してます、えのかわです。
先日、CloudWatch Events の Target に SSM Run Command が追加されました。
今回は、Auto Scaling の Lifecycle Hooks の TERMINATING をトリガーに、CloudWatch Events から SSM Run Commnad を呼んでみます。LAUNCHING に関しては、特に SSM を呼ぶ必要がなさそうなので、 User data を用いて初期設定を行います。
AutoScaling設定 ざっと aws cli を流します。
Launch Configuration作成 ベースとなる AMI には SSM Agent を導入している必要があります。今回の OS は AmazonLinux です。
$ aws autoscaling create-launch-configuration \ --launch-configuration-name test-web-lc \ --image-id ami-xxxxxx \ --key-name enokawa-kensho \ --security-groups sg-xxxxxxxx sg-xxxxxxxx \ --user-data file://userdata.txt \ --instance-type t2.</description>
    </item>
    
    <item>
      <title>AWS CodeCommitのアクティブユーザについて</title>
      <link>http://blog.enokawa.co/2016/10/20/about-the-aws-codecommit-active-user/</link>
      <pubDate>Thu, 20 Oct 2016 13:05:13 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2016/10/20/about-the-aws-codecommit-active-user/</guid>
      <description>はじめに こんにちは、えのかわです。
CodeCommitのアクティブユーザの定義について意味を理解していなかったので懺悔します。
甘かった僕の認識 最初の 5 人のアクティブユーザー*は無料」という表示で、「あっ、5つのIAMユーザまでは無料なんだ」と勘違いしていました。 しかし実際のドキュメントの内容は下記で、完璧に意味を履き違えていました。
  アクティブユーザーとは、その月に Git リクエストまたは AWS マネジメントコンソールを使用して AWS CodeCommit リポジトリにアクセスする、すべての固有の AWS Identity (IAM ユーザー、IAM ロール、フェデレーティッドユーザー、ルートアカウント) を指します。一意の AWS アイデンティティを使用して CodeCommit にアクセスするサーバーは、アクティブなユーザーとみなされます。その月に AWS CodeCommit にアクセスしていないユーザーに対しては料金が発生しません。ストレージには、リポジトリのデータを保持するために必要な容量全体が含まれます。   料金 - Amazon CodeCommit | AWS https://aws.amazon.com/jp/codecommit/pricing/
ということは 例えば5つのクライアントPCで同じIAMユーザ(SSH Key ID)を利用(Pull or Push)した場合、5アクティブユーザとしてみなされます。 僕の場合、1台のクライアントPCでPushやPullを行い、6台のEC2でpullのみを行いました。その結果additional CodeCommit user: 2 User-Monthとしてみなされました。
さいごに AWSのドキュメントはちゃんと読もうな、オレ。</description>
    </item>
    
    <item>
      <title>RDSのDB Engineのバージョン一覧をAWS CLIで確認する</title>
      <link>http://blog.enokawa.co/2016/10/06/describe-rds-db-engine-versions/</link>
      <pubDate>Thu, 06 Oct 2016 17:14:37 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2016/10/06/describe-rds-db-engine-versions/</guid>
      <description>はじめに こんにちは、えのかわです。
RDSのDB Engineのバージョン一覧をAWS CLI一発で確認する方法のメモです。
さっそく MySQLのバージョン一覧を確認してみます。
$ aws rds describe-db-engine-versions --engine mysql --query &#39;DBEngineVersions[].EngineVersion&#39; --output table -------------------------- |DescribeDBEngineVersions| +------------------------+ | 5.5.40 | | 5.5.40a | | 5.5.40b | | 5.5.41 | | 5.5.42 | | 5.5.46 | | 5.6.19a | | 5.6.19b | | 5.6.21 | | 5.6.21b | | 5.6.22 | | 5.6.23 | | 5.6.27 | | 5.6.29 | | 5.7.10 | | 5.7.11 | +------------------------+  Auroraの場合 Auroraの場合は単純に--engineパラメータを修正するのみです。</description>
    </item>
    
    <item>
      <title>特定のRoute53のHostedZoneのみの操作権限を与えたい</title>
      <link>http://blog.enokawa.co/2016/09/07/specific-route53-hostedzone-change/</link>
      <pubDate>Wed, 07 Sep 2016 21:00:37 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2016/09/07/specific-route53-hostedzone-change/</guid>
      <description>はじめに こんにちは、えのかわです。
特定のRoute53のHostedZoneのみを操作できるIAMユーザを作成したい場面があります。
そのIAMポリシーを作成したのでメモです。
HostedZoneの作成 まずRoute53が操作できる環境で２つのHostedZoneを作成します。 IAMユーザの作成 ポリシーは下記です。
&amp;lt;HostedZoneID&amp;gt;に、そのIAMユーザに操作させたいHotedZoneのIDを記載します。
今回は enokawa.me のHostedZoneIDを記載しました。
{ &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;, &amp;quot;Statement&amp;quot;: [ { &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Action&amp;quot;: [ &amp;quot;route53:ChangeResourceRecordSets&amp;quot;, &amp;quot;route53:GetHostedZone&amp;quot;, &amp;quot;route53:ListResourceRecordSets&amp;quot; ], &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:route53:::hostedzone/&amp;lt;HostedZoneID&amp;gt;&amp;quot; }, { &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Action&amp;quot;: [ &amp;quot;route53:GetChange&amp;quot; ], &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:route53:::change/*&amp;quot; } ] }  検証 作成したIAMユーザでAWSマネージメントコンソールにログインし、Route53にアクセスします。
権限エラーがでますね。 HostedZone一覧も閲覧できません。 下記の形式のURLでアクセスする必要があります。
https://console.aws.amazon.com/route53/home?region=ap-northeast-1#resource-record-sets:&amp;lt;HostedZoneID&amp;gt;  enokawa.me のHostedZoneIDを指定してアクセスしてみましょう。 わぁい
enokawa.org のHostedZoneIDを指定してアクセスすると何も表示されません。
想定通りの挙動です。 以下の警告文が表示されます。
 r53_user is not authorized to perform: route53:GetHostedZone on resource: hostedzone/HostedZoneID
 ALIASレコードは設定できるのか 前述したIAMポリシーにはS3やELB、CloudFrontなどの参照権限が記載されていないので、Alias Targetに候補は出てきません。 が、存在するELBのエンドポイントをペーストしてレコードを登録してみると、、、 お？</description>
    </item>
    
    <item>
      <title>OpsWorks &#43; CodeCommitでEC2をプロビジョニングする</title>
      <link>http://blog.enokawa.co/2016/05/14/opsworks-codecommit/</link>
      <pubDate>Sat, 14 May 2016 18:32:28 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2016/05/14/opsworks-codecommit/</guid>
      <description>はじめに こんにちは、えのかわです。 今回はOpsWorks(Chef)でEC2インスタンスをプロビジョニングする際にCodeCommitレポジトリを利用してみました。 色々とハマったのでブログで残しておきます。 OpsWorksとCodeCommitについては下記スライドをご参考ください。超ざっくり言うとOpsWorksはAWSに特化したChefサーバで、CodeCommitはGitレポジトリです。
  AWS OpsWorksハンズオン  from Amazon Web Services Japan 
  AWS Black Belt Tech シリーズ 2015 - AWS CodeCommit &amp;amp; AWS CodePipeline &amp;amp; AWS CodeDeploy  from Amazon Web Services Japan 
イメージ 図にするとこのような感じです。間違いがあったらご指摘ください。  クライアントPCからCodeCommitレポジトリにChefレシピをpush OpsWorks AgentがCodeCommitレポジトリをpull(更新) -&amp;gt; update_custom_cookbooks OpsWorks Agentがプロビジョニング(chef solo)を行う -&amp;gt; execute_recipes  CodeCommit用IAMユーザの作成 CodeCommitレポジトリへソースをプッシュするにはIAMユーザが必要になります。まず始めにCodeCommit専用のIAMユーザを作成します。ポリシーはひとまずAWSCodeCommitPowerUserを設定しておきます。 次にCodeCommitレポジトリにアクセスするためのSSHキーを設定します。Security CredentialsタブからUpload SSH public keyをクリックし、公開鍵を貼り付けてください。 公開鍵の設定が完了するとSSHアクセス用のIDが払い出されます。アクセスキーとは別です。 最後に~/.ssh/configにアクセス情報を記載しておきます。先ほど払い出されたSSH Key IDと、秘密鍵を指定します。
enokawa $ cat ~/.ssh/config Host git-codecommit.</description>
    </item>
    
    <item>
      <title>AWS CodeDeployを使ってでデプロイを自動化してみた</title>
      <link>http://blog.enokawa.co/2015/09/01/aws-codedeploy/</link>
      <pubDate>Tue, 01 Sep 2015 20:56:17 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2015/09/01/aws-codedeploy/</guid>
      <description>はじめに こんにちは、インフラエンジニア見習いのえのかわです。 今回は、AWS CodeDeployを使ってデプロイを自動化してみたのでログを残しておきます。 CodeDeployアプリケーションの作成は省略します。 下記のURLがとても参考になりました！
 http://www.ryuzee.com/contents/blog/7022 http://dev.classmethod.jp/cloud/codedeploy-ataglance/  イメージ 図にするとこのような感じです。間違いがあったらご指摘ください。  クライアントPCからプロジェクトを圧縮してS3にアップロード クライアントからCodeDeployのAPIを叩いてEC2(CodeDeploy Agent)にメタデータを渡す CodeDeploy AgentがS3にポーリングする S3から圧縮されたファイルをダウンロードして展開する  AppSpec.ymlの作成 appspec.ymlは以下のような形です。AppSpecについては、クラスメソッドさんの記事が大変参考になりました。
version: 0.0 os: linux files: - source: / destination: /var/www/html/ hooks: BeforeInstall: - location: scripts/install_dependencies timeout: 300 runas: root - location: scripts/start_server timeout: 300 runas: root ApplicationStop: - location: scripts/stop_server timeout: 300 runas: root  CodeDeployでプロジェクトをデプロイするには @ryuzeeさんのブログにも紹介されている通り、最終的には以下のコマンドを打たなければデプロイができません。(ポチポチでデプロイできるのかな？)
deploy pushコマンドでプロジェクトのファイルをzipにしてS3にアップロードします。
$ aws deploy push \ &amp;gt; --application-name CodeDeployTest \ &amp;gt; --s3-location s3://enokawa-test-bucket/app.</description>
    </item>
    
    <item>
      <title>DevOps採用システム自動構築ツール「SkyHopper」を使ってみた</title>
      <link>http://blog.enokawa.co/2015/08/09/skyhopper/</link>
      <pubDate>Sun, 09 Aug 2015 16:22:36 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2015/08/09/skyhopper/</guid>
      <description> はじめに こんにちは、インフラエンジニア見習いのえのかわです。
今回は株式会社スカイアーチネットワークスが開発したDevOps採用システム自動構築ツール「SkyHopper」を使ってみましたのでそのレポートを書きたいと思います。
今回はAmazon Linuxのt2.microを用いて構築します。 ゴールとしては、SkyHopperを利用してELB+EC2+RDSのよく見る構成を構築します。 SkyHopperとは ひと言でいうと、「ブラウザでAWSの構築ができてchefやServerspecが流せて監視ができるもの」ですかね。長いですね。笑
SkyHopperのインストール 基本的にはデプロイ手順を順番に進めていけば構築できます。 Cookbookも用意されているのでChefに慣れている方はChefで構築した方が楽かもしれません。
セットアップ 以下の図のように設定します。 構築が完了したら以下のコマンドを打ってskyhopperを再起動します。
$ cp -r ~/skyhopper/tmp/chef ~/.chef $ ./scripts/skyhopper_daemon.sh stop $ ./scripts/skyhopper_daemon.sh start  自動的に2台のインスタンスが構築されます。おそらくChefサーバーとZabbixサーバーです。EIPも関連付けられます。 サインアップ サインアップします。masterとadminの意味はまだ分かってないです。分かり次第、更新したいと思います。 顧客の作成 えのかわ株式会社から受注しました。顧客コードの決め方は規約を設けた方がいいと思いました。 案件の作成 えのかわ株式会社から公式HP作成の依頼が来たので新しく案件を作成します。アクセスキーとシークレットアクセスキーはお客様から頂きました。 新規インフラの作成 新しくインフラを構築します。EC2インスタンスも構築するので新しくキーペアーも登録します。新しく作成することもできます。 スタックの詳細（1） あらかじめ用意されているCloudFormationのテンプレートを用います。僕はWordPressのAMIを作成して、テンプレートにAMIを指定しました。 スタックの詳細（2） インスタンスタイプやDBの設定をすることができます。「送信」ボタンを押すと、CloudFormationのスタックが実行されます。 ブラウザでアクセスしてみる ELBのDNSでアクセスしてみます。お決まりのWordPressのセットアップ画面が表示されます。「データベースホスト」欄にRDSのDNS Nameを入力すれば完了です。2台のEC2のアクセスログをtailして負荷分散されることを確認します。 ハマったところ  鍵ペア名に.pemをいれてstack creation failedエラー Default VPCが存在していなくてエラー  気になったところ  ログにACCESSKEYとかSECRETACCESSKEYとか秘密鍵を吐いてるので気をつける必要があると思いました。
  </description>
    </item>
    
    <item>
      <title>NagiosのCloudWatchプラグインをつくってみた(PHP)</title>
      <link>http://blog.enokawa.co/2015/07/29/nagios-check-cloudwatch/</link>
      <pubDate>Wed, 29 Jul 2015 23:17:11 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2015/07/29/nagios-check-cloudwatch/</guid>
      <description>はじめに タイトルは釣りです。ごめんなさい。笑
cloudpack CTOの@suz_labさんがAWS SDK for PHP v1で作成したスクリプトをv2に書き直してみました(本人には了承済みです)。 前回の記事の続きで、今回はCloudWatchのプラグインを使ってEC2のリソースを監視してみたいと思います。
前提条件  NagiosサーバーににCloudWatch ReadOnly権限のIAM Roleが適用されていること phpがインストールされていること Nagiosサーバーの構築が済んでいること  AWS SDK for PHPをインストール まずはじめにAWS SDK for PHP v2をインストールします。インストールする場所はお好きなディレクトリで。
$ cd /opt/ $ sudo mkdir php-sdk2 $ sudo cd php-sdk2 $ sudo wget https://github.com/aws/aws-sdk-php/releases/download/2.8.14/aws.zip $ sudo unzip aws.zip $ sudo wget https://github.com/aws/aws-sdk-php/releases/download/2.8.14/aws.phar $ sudo vi composer.json #新しく作成 { &amp;quot;require&amp;quot;: { &amp;quot;aws/aws-sdk-php&amp;quot;: &amp;quot;2.*&amp;quot; } } $ sudo curl -sS https://getcomposer.org/installer | php $ sudo php composer.</description>
    </item>
    
    <item>
      <title>NagiosのNRPEプラグインを使ってログ監視をする</title>
      <link>http://blog.enokawa.co/2015/07/27/nagios-nrpe-checklog2/</link>
      <pubDate>Mon, 27 Jul 2015 21:06:43 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2015/07/27/nagios-nrpe-checklog2/</guid>
      <description>はじめに こんばんは、インフラエンジニア見習いのえのかわです。
前回の記事の続きです。今回は監視対象のログ監視をしたいと思います。
NRPE is 何 NRPE(Nagios Remote Plugin Executor)とは、監視対象サーバーに対して以下のような監視を実現したい時に用います。前回の記事ではpingを打つだけなのでNRPEは必要ではありませんでした。
 ディスク監視 CPU使用率の監視 メモリ使用率の監視 ログ監視  NRPEのインストール（Nagiosサーバー） それではさっそく設定していきます。まずはじめにNagiosサーバーにNRPE関連のパッケージをインストールします。 /usr/lib64/nagios/plugins/配下にcheck_nrpeというファイルがインストールされます。
$ sudo yum install nrpe nagios-plugins-nrpe  インストールしたcheck_nrpeコマンドを登録します。
$ sudo vi /etc/nagios/objects/commands.cfg define command{ command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$ }  NRPEのインストールと設定（監視対象サーバ） つづいて監視対象サーバに、NRPE関連のパッケージをインストールします。
$ sudo yum install -y epel-release $ sudo yum install nrpe nagios-plugins-nrpe nagios-plugins-all  nrpe.cfgに設定を書いていきます。Nagiosサーバーからのアクセスを許可します。
$ sudo cp -p /etc/nagios/nrpe.cfg.sample $ sudo vi /etc/nagios/nrpe.cfg allowed_hosts=127.</description>
    </item>
    
    <item>
      <title>CentOS6.6にNagiosサーバーをインストールする</title>
      <link>http://blog.enokawa.co/2015/07/26/nagios-server/</link>
      <pubDate>Sun, 26 Jul 2015 21:06:45 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2015/07/26/nagios-server/</guid>
      <description>はじめに こんばんは、インフラエンジニア見習いのえのかわです。
Nagiosサーバーの構築をEC2上で行ったので、備忘録として残したいと思います。
この記事のゴールとしては、Nagiosサーバーから監視対象のサーバーに対してpingでの死活監視ができることとします。
Nagiosのインストール NagiosはEPELリポジトリに登録されているので、EPELレポジトリを追加しておきます。
$ sudo yum install epel-release $ sudo yum install nagios nagios-plugins-all  アラートメールの設定 Nagiosのアラートメールが送信されるアドレスを登録します。デフォルトの設定ではnagios@localhostとなっているので任意のメールアドレスを設定します。
念の為にconfigのバックアップをとっておきましょう。
$ sudo cp -p /etc/nagios/objects/contacts.cfg /etc/nagios/objects/contacts.cfg.sample $ sudo vi /etc/nagios/objects/contacts.cfg email enokawa@example.com;  Apacheの設定 続いてApacheの設定です。BASIC認証の設定をします。
$ sudo cp -p /etc/httpd/conf.d/nagios.conf /etc/httpd/conf.d/nagios.conf.sample $ sudo vi /etc/httpd/conf.d/nagios.conf ScriptAlias /nagios/cgi-bin/ &amp;quot;/usr/lib64/nagios/cgi-bin/&amp;quot; &amp;lt;Directory &amp;quot;/usr/lib64/nagios/cgi-bin/&amp;quot;&amp;gt; Options ExecCGI AllowOverride None Order allow,deny Allow from all AuthName &amp;quot;Nagios Access&amp;quot; AuthType Basic AuthUserFile /etc/nagios/passwd Require valid-user &amp;lt;/Directory&amp;gt; Alias /nagios &amp;quot;/usr/share/nagios/html&amp;quot; &amp;lt;Directory &amp;quot;/usr/share/nagios/html&amp;quot;&amp;gt; Options None AllowOverride None Order allow,deny Allow from all AuthName &amp;quot;Nagios Access&amp;quot; AuthType Basic AuthUserFile /etc/nagios/passwd Require valid-user &amp;lt;/Directory&amp;gt;  続けてベーシック認証のパスワードを設定します。</description>
    </item>
    
    <item>
      <title>JAWS-UG初心者支部【第2回】懇親会でLTしてきました！！ #jawsug_bgnr</title>
      <link>http://blog.enokawa.co/2015/07/25/jawsug-beginner/</link>
      <pubDate>Sat, 25 Jul 2015 22:57:26 +0900</pubDate>
      
      <guid>http://blog.enokawa.co/2015/07/25/jawsug-beginner/</guid>
      <description>はじめに みなさんこんにちは、インフラエンジニア見習いのえのかわです。
先週の金曜日に行われたJAWS-UG初心者支部の懇親会でLTをしてきたのでそのレポートを書きます！
イベントページはこちら https://jawsug-beginner.doorkeeper.jp/events/26430
togetterはこちら http://togetter.com/li/848886
運営の加我さん参加者のレポートです。加我さんからは写真をお借りしてます！ありがとうございます！
第2回JAWS-UG 初心者支部(7&amp;frasl;17) - #ダメなら餃子 http://damenaragyouza.hatenablog.jp/entry/2015/07/21/143643
経緯 cloudpackエバンジェリストの@yoshidashingoさんに「LTしておいでや」と 言われたので久々に勉強会に参加させていただきました。正直、時間的にLTできないと思っていたので、ラッキーでした。
LTさせてくれた山崎さん、青木さん、運営のみなさん、ありがとうございました！！
勉強会 正直、勉強会自体は資料作りに夢中であまり話を聞けていたなかったので加我さんのブログを見ると雰囲気けっこう掴めると思います。次からは事前に準備して臨みたいと思います！
Piculet 今回のLTのテーマは「AWS初心者がCodenize.toolsでInfrastructure as Codeした話」です。 Codenize.toolsとはAWSのサービスをマイグレーション(移行)するツール群です。クックパッドの@sgwr_dtsさんが作成しています。 今回は、その中でもAWSのSecurity GroupsをマイグレーションするツールであるPiculetについて紹介しました！
Piculetの良さは--dry-runオプションが使える点です。applyする前に--dry-runで流して、他の人にレビューしてもらった後に applyする流れがいいと思います。Github(プライベートリポジトリなど)でレビューをしてもらうのもアリだと思います。
$ piculet -a -p prod -r ap-northeast-1 --dry-run   IAMユーザーの権限 Piculetを使用するIAMユーザーのポリシーは以下のような感じです。SGだけを操作できる最低限の権限だけを渡しておきます。 IP制限をかけておくとよりセキュアに運用できると思います。
{ &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;, &amp;quot;Statement&amp;quot;: [ { &amp;quot;Sid&amp;quot;: &amp;quot;Stmt0000000000001&amp;quot;, &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Action&amp;quot;: [ &amp;quot;ec2:DescribeSecurityGroups&amp;quot;, &amp;quot;ec2:DescribeTags&amp;quot;, &amp;quot;ec2:AuthorizeSecurityGroupEgress&amp;quot;, &amp;quot;ec2:AuthorizeSecurityGroupIngress&amp;quot;, &amp;quot;ec2:RevokeSecurityGroupIngress&amp;quot;, &amp;quot;ec2:RevokeSecurityGroupEgress&amp;quot;, &amp;quot;ec2:CreateSecurityGroup&amp;quot;, &amp;quot;ec2:DeleteSecurityGroup&amp;quot; ], &amp;quot;Condition&amp;quot;: { &amp;quot;IpAddress&amp;quot;: { &amp;quot;aws:SourceIp&amp;quot;: &amp;quot;XX.XX.XX.XX&amp;quot; } }, &amp;quot;Resource&amp;quot;: [ &amp;quot;*&amp;quot; ] } ] }  おわりに 今回はPiculetを紹介しましたが、Codenize.</description>
    </item>
    
  </channel>
</rss>